import java.io.File;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.nio.file.StandardCopyOption;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;

import org.alfresco.service.ServiceRegistry;
import org.alfresco.service.cmr.repository.NodeRef;
import org.alfresco.service.cmr.repository.NodeService;
import org.alfresco.service.cmr.repository.StoreRef;
import org.alfresco.service.namespace.QName;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import com.opencsv.CSVReader;
import com.opencsv.CSVWriter;
import com.opencsv.exceptions.CsvValidationException;

public class UpdateDocDescScheduledJobExecuter {

    private static final Logger logger = LoggerFactory.getLogger(UpdateDocDescScheduledJobExecuter.class);

    public static final String NAMESPACE_JH_CONTENT_MODEL = "http://www.alfresco.org/model/johnhancock/1.0";
    public static final QName PROP_JH_DOCUMENT_DESCRIPTION = QName.createQName(NAMESPACE_JH_CONTENT_MODEL, "documentDescription");

    private ServiceRegistry serviceRegistry;
    private CSVProcessor updateDocDescCSVProcessor;

    public void execute() {
        logger.info("Running the Update Document Description Scheduled Job Executer");
        try {
            File[] csvFiles = updateDocDescCSVProcessor.getCSVReports();

            if (csvFiles.length > 0) {
                int numFilestoPick = Math.min(1, csvFiles.length);
                for (int i = csvFiles.length - 1; i >= csvFiles.length - numFilestoPick; i--) {
                    boolean hasAnyFailures = false;
                    File csvFile = csvFiles[i];
                    String inputFilePath = csvFile.getAbsolutePath();

                    String successFilePath = updateDocDescCSVProcessor.getSOURCE_CSV_LOC() + "/"
                            + CommonConstants.SUCCESS_CSV_LOC_NAME + "/" + csvFile.getName();
                    String failureFilePath = updateDocDescCSVProcessor.getSOURCE_CSV_LOC() + "/"
                            + CommonConstants.ERROR_CSV_LOC_NAME + "/" + csvFile.getName();

                    try (CSVReader reader = new CSVReader(new FileReader(inputFilePath));
                            CSVWriter successFilewriter = new CSVWriter(new FileWriter(successFilePath));
                            CSVWriter failureFilewriter = new CSVWriter(new FileWriter(failureFilePath))) {

                        String[] header = reader.readNext();
                        String[] newHeader = addColumn(header, "Status");

                        successFilewriter.writeNext(newHeader);
                        failureFilewriter.writeNext(newHeader);

                        String[] nextLine;
                        ExecutorService executor = Executors.newFixedThreadPool(4); // Adjust the number of threads as needed
                        while ((nextLine = reader.readNext()) != null) {
                            String[] row = nextLine;

                            // Process each row in a separate thread
                            executor.submit(() -> processAndWriteRow(row, header, successFilewriter, failureFilewriter));

                            // Wait for half a second before moving to the next job
                            Thread.sleep(100);
                        }
                        executor.shutdown();
                        executor.awaitTermination(Long.MAX_VALUE, TimeUnit.NANOSECONDS);
                    } catch (IOException | CsvValidationException e) {
                        logger.error("Error processing CSV file: " + e.getMessage(), e);
                    } finally {
                        try {
                            Files.move(Paths.get(csvFile.getAbsolutePath()),
                                    Paths.get(updateDocDescCSVProcessor.getSOURCE_CSV_LOC() + File.separator
                                            + CommonConstants.ARCHIVE_CSV_LOC_NAME + "/" + csvFile.getName()),
                                    StandardCopyOption.REPLACE_EXISTING);
                        } catch (IOException e) {
                            logger.error("Error moving CSV file to archive: " + e.getMessage(), e);
                        }
                        if (!hasAnyFailures) {
                            try {
                                Files.deleteIfExists(Paths.get(failureFilePath));
                            } catch (IOException e) {
                                logger.error("Error deleting failure file: " + e.getMessage(), e);
                            }
                        }
                    }
                    // Adding a sleep time for 10 seconds
                    Thread.sleep(10000);
                }
            } else {
                logger.info("No document found under " + updateDocDescCSVProcessor.getSOURCE_CSV_LOC()
                        + " for Update Document Description Stateful JobScheduler");
            }
        } catch (Exception e) {
            logger.error("Error while processing the csv batches: " + e.getMessage(), e);
        }
    }

    private void processAndWriteRow(String[] row, String[] header, CSVWriter successFilewriter,
            CSVWriter failureFilewriter) {
        String[] processedRow = processRow(row);

        if (processedRow != null && processedRow.length > header.length) {
            String status = processedRow[header.length];

            if ("Success".equalsIgnoreCase(status)) {
                successFilewriter.writeNext(processedRow);
            } else {
                failureFilewriter.writeNext(processedRow);
            }
        }
    }

    private String[] addColumn(String[] row, String columnName) {
        String[] newRow = new String[row.length + 1];
        System.arraycopy(row, 0, newRow, 0, row.length);
        newRow[row.length] = columnName;
        return newRow;
    }

    private String[] processRow(String[] row) {
        // Implement your row processing logic, making sure it is thread-safe
        String status = null;

        if (row.length >= 2) {

            try {
                String nodeId = row[0].trim();
                String nodeDescription = row[1].trim();

                NodeService nodeService = serviceRegistry.getNodeService();
                StoreRef storeRef = new StoreRef(StoreRef.PROTOCOL_WORKSPACE, "SpacesStore");

                NodeRef nodeRef = new NodeRef(storeRef, nodeId);

                if (nodeService.exists(nodeRef)) {
                    nodeService.setProperty(nodeRef, PROP_JH_DOCUMENT_DESCRIPTION, nodeDescription);
                    logger.debug("Node " + nodeId + "updated successfully ");
                    status = "Success";
                } else {
                    status = "Error:: Node not found";
                    logger.error("Error updating the node :: Node not found: " + nodeId);
                }
            } catch (Exception e) {
                status = "Error:: Error Updating Node ID";
                logger.error("Error updating the node ::  " + e.getMessage());
                e.printStackTrace();
            }

        } else {
            status = "Error:: Invalid CSV Row";
            logger.error("Invalid CSV row: " + row);
        }
        return addColumn(row, status);
    }

    public void setServiceRegistry(ServiceRegistry serviceRegistry) {
        this.serviceRegistry = serviceRegistry;
    }

    public void setUpdateDocDescCSVProcessor(CSVProcessor updateDocDescCSVProcessor) {
        this.updateDocDescCSVProcessor = updateDocDescCSVProcessor;
    }
}
